import pandas as pd
import re
import glob
from datetime import datetime
import os
import requests
from zipfile import ZipFile
from io import BytesIO
from urllib.parse import urlparse, parse_qs

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By

def fetch_eCO2mix_data(destination_folder="../data/external/"):
    """
    T√©l√©charge et extrait tous les fichiers ZIP de la div .eco2mix-download-data
    sur la page des indicateurs √©CO2mix de RTE.
    
    Args:
        destination_folder (str): Dossier o√π extraire les fichiers.
    """
    os.makedirs(destination_folder, exist_ok=True)

    page_url = "https://www.rte-france.com/eco2mix/telecharger-les-indicateurs"

    # Setup Selenium headless
    chrome_opts = Options()
    chrome_opts.add_argument("--headless")
    driver = webdriver.Chrome(options=chrome_opts)

    try:
        print(f"üåê Chargement de {page_url}")
        driver.get(page_url)
        driver.implicitly_wait(10)

        # S√©lectionne tous les liens <a> de la div cible
        anchors = driver.find_elements(By.CSS_SELECTOR, "div.eco2mix-download-data a")

        # Filtre : on garde les .zip et les calendriers Tempo
        download_links = []
        for a in anchors:
            href = a.get_attribute("href")
            if not href:
                continue
            low = href.lower()
            if low.endswith(".zip") or "downloadcalendriertempo" in low:
                download_links.append(href)

        print(f"üîó {len(download_links)} liens d√©tect√©s (ZIP + Tempo).")

        for url in download_links:
            parsed = urlparse(url)
            name = os.path.basename(parsed.path)
            
            # --- Traitement ZIP ---
            print(f"‚¨áÔ∏è  T√©l√©chargement ZIP : {name}")
            resp = requests.get(url)
            resp.raise_for_status()
            with ZipFile(BytesIO(resp.content)) as zf:
                for member in zf.infolist():
                    if member.is_dir():
                        continue
                    fname = os.path.basename(member.filename)
                    if not fname:
                        continue
                    out_path = os.path.join(destination_folder, fname)
                    with zf.open(member) as src, open(out_path, "wb") as dst:
                        dst.write(src.read())
            print(f"‚úÖ Contenu de {name} extrait dans {destination_folder}")

    finally:
        driver.quit()

def convert_xls_eCO2mix_to_csv(input_path, output_path):
    """
    Convertit un fichier .xls (format texte tabul√©) en .csv propre.

    Cette fonction effectue les op√©rations suivantes :
    1. Lit un fichier .xls en supposant qu'il est encod√© en cp1252.
    2. Remplace les tabulations ('\\t') par des virgules (',').
    3. Supprime une virgule finale superflue sur chaque ligne sauf l‚Äôen-t√™te.
    4. Supprime la ligne de disclaimer RTE si elle est pr√©sente.
    5. S'assure que chaque ligne du fichier de sortie se termine par un seul saut de ligne.
    6. Enregistre le r√©sultat final encod√© en UTF-8.

    Param√®tres :
    ----------
    input_path : str
        Chemin vers le fichier .xls d'entr√©e (fichier texte avec tabulations).
    output_path : str
        Chemin vers le fichier .csv nettoy√© √† produire.

    Exemple :
    --------
    convert_xls_to_clean_csv(
        input_path='../data/raw/eCO2mix_RTE_En-cours-TR.xls',
        output_path='../data/processed/eCO2mix_clean.csv'
    )
    """
    with open(input_path, 'r', encoding='cp1252') as f:
        lines = f.readlines()

    cleaned_lines = []
    for i, line in enumerate(lines):
        # Supprimer ligne de disclaimer si elle correspond
        if "RTE ne pourra" in line:
            continue
        if "L'ensemble des informations disponibles" in line:
            continue

        # Remplacer les tabulations par des virgules
        line = line.replace('\t', ',')

        # Supprimer une √©ventuelle virgule en trop √† la fin (sauf pour l'en-t√™te)
        if i > 0:
            line = re.sub(r',\s*$', '', line)

        # S'assurer que chaque ligne finit par un seul \n
        line = line.rstrip() + '\n'

        cleaned_lines.append(line)

    # Sauvegarde dans un nouveau fichier CSV
    with open(output_path, 'w', encoding='utf-8') as f:
        f.writelines(cleaned_lines)

    print(f"‚úÖ Fichier converti et nettoy√© : {output_path}")

def convert_all_xls_eCO2mix_data(xls_path, csv_path):
    """
    Convertit tous les fichiers .xls dans le dossier d'entr√©e en fichiers .csv nettoy√©s.
    Param√®tre : 
    xls_path : str
        Chemin vers le dossier contenant les fichiers .xls √† convertir.
    csv_path : str
        Chemin vers le dossier o√π les fichiers .csv nettoy√©s seront enregistr√©s.
    """
    xls_files = glob.glob(os.path.join(xls_path, "*.xls"))
    raw_csv_paths = []
    for xls_path in xls_files:
        # Convertit les fichiers XLS en CSV
        base_name = os.path.basename(xls_path).replace(".xls", ".csv")
        out_path = os.path.join(csv_path, base_name)
        convert_xls_eCO2mix_to_csv(xls_path, out_path)
        raw_csv_paths.append(out_path)

def load_data(filepath, encoding='utf-8', sep=","):
    """
    Charge les donn√©es depuis un fichier TXT avec des champs s√©par√©s par une tabulation,
    et convertit la colonne de date.

    Param√®tres :
    - filepath : chemin du fichier TXT.
    - date_column : nom de la colonne contenant les dates.

    Retourne :
    - DataFrame contenant les donn√©es avec la colonne date convertie en datetime.
    """
    try:
        data = pd.read_csv(filepath, sep=sep, encoding=encoding, low_memory=False, dtype=str)
        return data
    except Exception as e:
        print(f"Erreur lors du chargement des donn√©es : {e}")
        return None

def preprocess_annual_data(df):
    """
    Pr√©traite les donn√©es annuelles :
    - Convertit la colonne 'Date' & 'Heure' en 'Datetime'.
    - Supprime les colonnes inutiles.

    Param√®tres :
    - df : DataFrame √† pr√©traiter.

    Retourne :
    - DataFrame pr√©trait√©.
    """
    
    assert 'Consommation' in df.columns, "La colonne 'Consommation' est requise."
    assert 'Date' in df.columns, "La colonne 'Date' est requise."
    assert 'Heures' in df.columns, "La colonne 'Heures' est requise."
    
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce', format="%Y-%m-%d")
    # Creation de Datetime
    df['Datetime'] = pd.to_datetime(df['Date'].dt.strftime("%Y-%m-%d") + " " + df['Heures'], 
                                format="%Y-%m-%d %H:%M", errors='coerce')
    df = df.drop_duplicates()
    # Supprimer les colonnes inutiles
    columns_to_drop = df.columns.difference(['Date', 'Heures', 'Datetime', 'Consommation'])
    df = df.drop(columns=columns_to_drop, errors='ignore', axis=1)
    df = df.dropna(subset=['Consommation'])
    return df

def one_hot_encode(df, column):
    """
    Effectue un encodage one-hot sur une colonne donn√©e d'un DataFrame.

    Param√®tres :
    - df : DataFrame √† encoder.
    - column : nom de la colonne √† encoder.

    Retourne :
    - DataFrame avec la colonne encod√©e.
    """
    if column not in df.columns:
        raise ValueError(f"La colonne '{column}' n'existe pas dans le DataFrame.")
    
    one_hot = pd.get_dummies(df[column], prefix=column)
    df = df.drop(column, axis=1)
    df = pd.concat([df, one_hot], axis=1)
    return df

def preprocess_tempo_data(df):
    """
    Pr√©traite la donn√©e TEMPO de eCO2mix : 
    - Applique le one-hot encoding sur la colonne TEMPO (i.e 'Type de jour TEMPO').
    
    Param√®tres :
    - df : DataFrame TEMPO √† pr√©traiter.
    
    Retourne : 
    - DataFrame pr√©trait√©.
    """
    assert 'Type de jour TEMPO' in df.columns, "La colonne 'Type de jour TEMPO' est requise."
    df['Date'] = pd.to_datetime(df['Date'], errors='coerce', format="%Y-%m-%d")
    return one_hot_encode(df, 'Type de jour TEMPO')

def concat_eCO2mix_annual_data(path_annual):
    """
    Concat√®ne tous les fichiers annuels de eCO2mix dans un seul DataFrame.

    Param√®tres :
    - path_annual : chemin vers le dossier contenant les fichiers annuels.

    Retourne :
    - DataFrame concat√©n√©.
    """
    pattern_annuel  = os.path.join(path_annual, "eCO2mix_RTE_Annuel-Definitif_20*.csv")
    pattern_consol  = os.path.join(path_annual, "eCO2mix_RTE_En-cours-Consolide.csv")
    pattern_realtime = os.path.join(path_annual, "eCO2mix_RTE_En-cours-TR.csv")
    annual_files = sorted(glob.glob(pattern_annuel)) + [pattern_consol, pattern_realtime]
    list_df_annual = []
    # Assertion pour v√©rifier que tous les fichiers existent
    missing_files = [f for f in annual_files if not os.path.isfile(f)]
    assert not missing_files, f"Fichiers manquants : {missing_files}"
    print("Lecture des fichiers annuels :")
    for file in annual_files:
        print("  -", file)
        
        df = load_data(file, encoding="utf-8")
        if df is not None:
            # Vous pouvez √©galement ajouter des transformations propres aux fichiers annuels ici si n√©cessaire
            list_df_annual.append(df)

    # Concat√©nation de toutes les donn√©es annuelles en un seul DataFrame
    df_annual = pd.concat(list_df_annual, axis=0, ignore_index=False)
    # Remise √† z√©ro de l'index si besoin (sinon, vous conservez l'index fourni par le fichier source)
    df_annual.reset_index(drop=True, inplace=True)
    return df_annual

def concat_eCO2mix_tempo_data(path_tempo):
    """
    Concat√®ne tous les fichiers TEMPO de eCO2mix dans un seul DataFrame.
    Param√®tres :
    - path_tempo : chemin vers le dossier contenant les fichiers tempo.

    Retourne :
    - DataFrame concat√©n√©.
    """
    tempo_pattern = os.path.join(path_tempo, "*.csv")
    tempo_files = sorted(glob.glob(tempo_pattern))
    list_df_tempo = []
    # Assertion pour v√©rifier que tous les fichiers existent
    assert tempo_files, f"Aucun fichier trouv√© avec le pattern : {tempo_pattern}"
    
    print("Lecture des fichiers tempo :")
    for file in tempo_files:
        print("  -", file)
        try:
            df = load_data(file, encoding="utf-8")
            # Vous pouvez √©galement ajouter des transformations propres aux fichiers tempo ici si n√©cessaire
            list_df_tempo.append(df)
        except Exception as e:
            print(f"Erreur lors de la lecture du fichier {file}: {e}")
    df_tempo = pd.concat(list_df_tempo, axis=0, ignore_index=True)
    return df_tempo

def merge_eCO2mix_data(df_annual, df_tempo):
    """
    Fusionne les donn√©es annuelles et TEMPO sur la colonne 'Date'.

    Param√®tres :
    - df_annual : DataFrame des donn√©es annuelles.
    - df_tempo : DataFrame des donn√©es TEMPO.

    Retourne :
    - DataFrame fusionn√©.
    """
    assert 'Date' in df_annual.columns, "La colonne 'Date' est requise dans df_annual."
    assert 'Date' in df_tempo.columns, "La colonne 'Date' est requise dans df_tempo."
    
    df_tempo['Date'] = pd.to_datetime(df_tempo['Date'], errors='coerce', format="%Y-%m-%d")
    df_annual['Date'] = pd.to_datetime(df_annual['Date'], errors='coerce', format="%Y-%m-%d")
    
    merged_df = pd.merge(df_annual, df_tempo, on='Date', how='left')
    return merged_df

def preprocess_eCO2mix_data(df):
    """
    Pr√©traite les donn√©es fusionn√©es de eCO2mix :
    - Supprime les lignes ou il existe aucune valeur dans les colonnes 'Type de jour TEMPO_BLEU', 'Type de jour TEMPO_BLANC', 'Type de jour TEMPO_ROUGE'.
    - index√© par 'Datetime'.

    Param√®tres :
    - df : DataFrame fusionn√© √† pr√©traiter.
    
    Retourne:
    - DataFrame pr√©trait√©.
    """
    assert 'Datetime' in df.columns, "La colonne 'Datetime' est requise."
    assert 'Type de jour TEMPO_BLEU' in df.columns, "La colonne 'Type de jour TEMPO_BLEU' est requise."
    assert 'Type de jour TEMPO_BLANC' in df.columns, "La colonne 'Type de jour TEMPO_BLANC' est requise."
    assert 'Type de jour TEMPO_ROUGE' in df.columns, "La colonne 'Type de jour TEMPO_ROUGE' est requise."
    
    # Supprime les lignes o√π il n'y a aucune valeur dans les colonnes TEMPO
    df = df.dropna(subset=['Type de jour TEMPO_BLEU', 'Type de jour TEMPO_BLANC', 'Type de jour TEMPO_ROUGE'], how='all')
    
    # Indexe par Datetime
    df.set_index('Datetime', inplace=True)
    
    return df

def preprocess_eCO2mix_data_engineered(df):
    """
    Pr√©traite les donn√©es de eCO2mix apr√®s ing√©nierie des caract√©ristiques :
        - Supprime les lignes qui ne poss√®de pas les donn√©es features lag, rolling mean vide.
    
    Retourne :
        - DataFrame pr√©trait√©.
    """
    engineered_cols = [col for col in df.columns if any(
        kw in col.lower() for kw in ['lag', 'rolling'])]

    assert engineered_cols, "Aucune colonne d'ing√©nierie d√©tect√©e dans le DataFrame."

    # Suppression des lignes contenant des NaN dans les colonnes d'ing√©nierie
    df_cleaned = df.dropna(subset=engineered_cols)
    return df_cleaned
    